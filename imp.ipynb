{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os \n",
    "\n",
    "t5_generated_dataset_dir = \"/home/deokhk/research/HotpotQA_longformer/data/t5_generated\"\n",
    "\n",
    "t5_gen_train_path = os.path.join(t5_generated_dataset_dir, \"t5_train_generated.json\")\n",
    "t5_gen_valid_path = os.path.join(t5_generated_dataset_dir, \"t5_valid_generated.json\")\n",
    "\n",
    "with open(t5_gen_train_path, 'r') as f: \n",
    "    gen_train = json.load(f)\n",
    "\n",
    "with open(t5_gen_valid_path, 'r') as f: \n",
    "    gen_valid = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45212, 7404)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_train), len(gen_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cleaned = []\n",
    "\n",
    "for datapoint in gen_train: \n",
    "    cleaned_qapair = dict()\n",
    "    mycontext = \"\"\n",
    "    context_titles = datapoint[\"context\"][\"title\"]\n",
    "    context_sentences_list = datapoint[\"context\"][\"sentences\"]\n",
    "    question = datapoint[\"question\"]\n",
    "    mycontext = \"<yes> <no> \"\n",
    "    for title, sentence_list in zip(context_titles, context_sentences_list):\n",
    "        for sentence in sentence_list:\n",
    "            mycontext += sentence\n",
    "        mycontext += \"\\n\"\n",
    "    answer_text = datapoint[\"answer\"]\n",
    "    if answer_text in mycontext:\n",
    "        answer_start_idx = mycontext.index(answer_text)\n",
    "    else:\n",
    "        print(\"Skipped this qapair. The answer does not exist as a span in the context.\")\n",
    "        continue \n",
    "        \n",
    "    cleaned_qapair[\"question\"] = question \n",
    "    cleaned_qapair[\"answers\"] = {\"text\": [answer_text], \"answer_start\": [answer_start_idx]}\n",
    "    cleaned_qapair[\"context\"] = mycontext \n",
    "    cleaned_qapair[\"id\"] = datapoint[\"id\"]\n",
    "    train_data_cleaned.append(cleaned_qapair)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longformer evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음 우선 model을 불러와야 되고 \n",
    "# 그리고 pipeline이 제대로 작동하는지 check하기 위해서 일단은 dev set에 대해서 한번 test는 해봐야될듯?\n",
    "# \n",
    "import torch \n",
    "from transformers import pipeline, AutoTokenizer\n",
    "pretrained_model_path = \"/home/deokhk/research/longformer_trained_models/hotpotqa_simple\"\n",
    "\n",
    "mytokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "infer_device = torch.device(\"cuda:0\")\n",
    "pipe = pipeline(\"question-answering\", device=infer_device, model=pretrained_model_path, tokenizer=mytokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset hotpot_qa (/home/deokhk/.cache/huggingface/datasets/hotpot_qa/distractor/1.0.0/133b9501f892e5193babbad937bee3b4899deb4691ef4d791e6ac0111c875bb5)\n",
      "100%|██████████| 2/2 [00:00<00:00, 676.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from model_util import load_hotpotqa_for_longformer_dire_qa_simple \n",
    "d = load_hotpotqa_for_longformer_dire_qa_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = d[\"validation\"]\n",
    "from tqdm.auto import tqdm \n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "for idx, datapoint in enumerate(tqdm(valid_dataset)):    \n",
    "    question = datapoint[\"question\"]\n",
    "    context = datapoint[\"context\"]\n",
    "    predicted = pipe(question=question, context=context)\n",
    "    if idx == 50:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "import evaluate \n",
    "metric = evaluate.load(\"squad\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIRE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99356c42dab3e7ebcf92c0f63dbc419f3fb3a80f76e36742134f3dd0fe9401f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
